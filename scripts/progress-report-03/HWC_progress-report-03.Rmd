---
title: "Final Project Project Report 3"
author: "Isaac Chen"
date: "`r format(Sys.time(), '%B %d, %Y')`"
---

## Setup

```{r}
#| label: setup
#| message: false

# Clear all the variables in the environment
rm(list = ls())

# Print warnings immediately as they come up for troubleshooting purposes
options(warn = 1)

# Load packages
library(here) # Used to find files relative to my project root
library(tidyverse) # Used to tidying data
library(tidymodels) # Used for modeling and machine learning
library(skimr) # Used to create data summary
library(ggrain) # Used to create raincloud plots

# For reproducibility
set.seed(123)
```

## Objective

Data for this project comes from the [Baby's First Years (BFY)](https://www.childandfamilydataarchive.org/cfda/archives/cfda/studies/37871/summary) project. The objective of this project is to use demographic and background characters collected shortly after birth to predict language skills at age 1.

## Load Data

```{r}
# Load data
baseline <- here("data", "ICPSR_37871", "DS0001", "37871-0001-Data.rda")
age1 <- here("data", "ICPSR_37871", "DS0002", "37871-0002-Data.rda")

load(baseline)
load(age1)
```

## Data cleaning

```{r}
# Combine language outcome from age 1 dataset with baseline dataset based on ID
age1 <- da37871.0002 |> 
  select(PUBLICSAMPLEID, CASQLANGA1)

# Join by keeping all observations in age 1 data
bfy <- da37871.0001 |> 
  right_join(age1, by = join_by(PUBLICSAMPLEID))

# Remove columns that contains only NAs
# Remove columns that contains only 1 type of value
# Remove rows with missing outcome data
bfy <- bfy |> 
  select(where(~ !all(is.na(.)))) |> 
  select(where(~ !n_distinct(na.omit(.)) == 1)) |> 
  filter(!is.na(CASQLANGA1)) 
```

```{r}
# Data summary
skim(bfy)
```

## Data exploration

### Univariate analyses

```{r}
# Raincloud plot
bfy |> 
  ggplot(aes(1, CASQLANGA1)) + 
  geom_rain(boxplot.args = list(outlier.color = "red")) + 
  labs(y = "Standardized ASQ Communication Langauge Scores") + 
  scale_y_continuous(limits = c(-3.5, 3.5), breaks = seq(-3, 3, 1)) + 
  theme_classic() + 
  theme(
    axis.title.y = element_blank(),
    axis.text.y = element_blank(), 
    axis.ticks.y = element_blank()
  ) +
  coord_flip()
```

### Bivariate analyses

```{r}
# Bar chart
bfy |> 
  group_by(TREATA0) |> 
  summarize(mean = round(mean(CASQLANGA1, na.rm = TRUE), 3)) |> 
  ggplot(aes(x = TREATA0, y = mean, fill = TREATA0)) +
  geom_col(alpha = 0.5, width = 0.5) + 
  geom_text(aes(label = paste0(mean), hjust = -0.5)) +
  scale_y_continuous(limits = c(0, 0.7), breaks = seq(0, 0.7, 0.1)) + 
  labs(
    x = "Treatment group",
    y = "Standardized ASQ Communication Langauge Scores"
  ) +
  coord_flip() +
  theme_bw() +
  theme(legend.position = "none")
```

```{r}
# Bar chart
bfy |> 
  filter(!is.na(SERVICESSUPPORT_S_1A0)) |> 
  group_by(SERVICESSUPPORT_S_1A0) |> 
  summarize(mean = round(mean(CASQLANGA1, na.rm = TRUE), 3)) |> 
  ggplot(aes(x = SERVICESSUPPORT_S_1A0, y = mean, fill = SERVICESSUPPORT_S_1A0)) +
  geom_col(alpha = 0.5, width = 0.5) + 
  geom_text(aes(label = paste0(mean), hjust = -0.5)) +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) + 
  labs(
    x = "Services and Suppor (first reported)",
    y = "Standardized ASQ Communication Langauge Scores"
  ) +
  coord_flip() +
  theme_bw() +
  theme(legend.position = "none")
```

```{r}
# Scatterplot chart
bfy |> 
  ggplot(aes(x = MOMEDUYRSA0, y = CASQLANGA1)) +
  geom_point() +
  geom_smooth(method = "loess", se = F) +
  scale_x_continuous(limits = c(0, 35), breaks = seq(0, 35, 5)) + 
  scale_y_continuous(limits = c(-3.5, 1.5), breaks = seq(-3.5, 1.5, 0.5)) + 
  labs(
    x = "Mother's Education (years)",
    y = "Standardized ASQ Communication Langauge Scores"
  ) +
  theme_bw()
```

## Model construction

### Training and Testing

```{r}
# Split data into training set (75%) and testing set (25%)
bfy_split <- initial_split(bfy)
bfy_train <- training(bfy_split)
bfy_test <- testing(bfy_split)
```

### Setting the formula and recipe

```{r}
# Define formula for linear regression
bfy_formula <- as.formula("CASQLANGA1 ~ .")

# Define pre-processing steps
bfy_recipe <- bfy |> 
  recipe(bfy_formula) |> 
  update_role(CASQLANGA1, new_role = "outcome") |> 
  update_role(PUBLICSAMPLEID, new_role = "id") |> 
  step_filter_missing(all_predictors(), threshold = 0.1) |> 
  step_other(all_nominal_predictors(), threshold = 0.01) |> 
  step_impute_mode(all_nominal_predictors()) |> 
  step_impute_mean(all_numeric_predictors()) |> 
  step_dummy(all_nominal_predictors()) |> 
  step_zv(all_predictors()) |>
  step_corr(all_predictors(), threshold = 0.95) |> 
  step_normalize(all_predictors())
```

```{r}
# Apply transformations on training set and look at results
bfy_recipe |> prep() |> bake(bfy_train) |> head()
```

### Model specifications

```{r}
# Define elastic net model
bfy_tune_model <- 
  linear_reg(penalty = tune(), mixture = tune()) |> 
  set_engine("glmnet")
```

```{r}
# Set up workflow
bfy_wf <- 
  workflow() |> 
  add_model(bfy_tune_model) |> 
  add_recipe(bfy_recipe)
```

## Hyperparameter training

```{r}
# Set up grid and default values for parameters
enet_grid <- 
  grid_regular(
    extract_parameter_set_dials(bfy_tune_model), 
    levels = 10
  )
```

```{r}
# Monte Carlo resampling on training data
bfy_rs <- mc_cv(bfy_train, times = 25, prop = 0.75)
```

```{r}
# Run model on the resampled data
bfy_enet_fit <- bfy_wf |> 
    tune_grid(bfy_rs, grid = enet_grid)
```

## Choosing the best model

```{r}
# Determine best combination of penalty and mixture for lowest rmse
bfy_enet_fit |> 
  collect_metrics() |> 
  filter(.metric == "rmse") |> 
  arrange(mean)
```

```{r}
# Plot 
bfy_enet_fit |> 
  collect_metrics() |> 
  mutate(mixture = as_factor(round(mixture, 2))) |> 
  filter(.metric == "rmse") |> 
  rename_with(~str_to_title(.)) |> 
  rename(RMSE = Mean) |>
  ggplot(aes(y = RMSE, x = Penalty, color = Mixture)) +
  geom_line()+
  facet_wrap(~ Mixture, nrow = 2)+
  theme_minimal()
```

```{r}
# Best parameters based on rmse
best_enet_params <- bfy_enet_fit |> 
  select_best(metric = "rmse")

best_enet_params
```

```{r}
# Finalize workflow
final_enet_wf <- bfy_wf |> finalize_workflow(best_enet_params)
```

```{r}
# Apply finalized model on training set and then compare it with validation set
final_enet_model <- last_fit(final_enet_wf, bfy_split)
```

```{r}
# Evaluate model performance
collect_metrics(final_enet_model)
```
