---
title: "Final Project Project Report 3 (Elastic Net)"
author: "Isaac Chen"
date: "`r format(Sys.time(), '%B %d, %Y')`"
---

## Setup

```{r}
#| label: setup
#| message: false

# Clear all the variables in the environment
rm(list = ls())

# Print warnings immediately as they come up for troubleshooting purposes
options(warn = 1)

# Load packages
library(here) # Used to find files relative to my project root
library(haven) # Used to read in SPSS datasets
library(tidyverse) # Used to tidying data
library(tidymodels) # Used for modeling and machine learning
library(skimr) # Used to create data summary
library(ggrain) # Used to create raincloud plots

# For reproducibility
set.seed(123)
```

## Objective

Data for this project comes from the [Baby's First Years (BFY)](https://www.childandfamilydataarchive.org/cfda/archives/cfda/studies/37871/summary) project. The objective of this project is to use demographic and background characters collected shortly after birth to predict language skills at age 1.

## Load Data

```{r}
#| label: load_data
# Define paths to R data files
baseline_path <- here("data", "ICPSR_37871", "DS0001", "37871-0001-Data.sav")
age1_path <- here("data", "ICPSR_37871", "DS0002", "37871-0002-Data.sav")

baseline <- read_sav(baseline_path)
age1 <- read_sav(age1_path)
```

## Data cleaning

```{r}
#| label: clean_data
# Combine language outcome from age 1 dataset with baseline dataset based on ID
age1 <- age1 |> 
  select(PUBLICSAMPLEID, CASQLANGA1)

# Join by keeping all observations in age 1 data
bfy <- baseline |> 
  right_join(age1, by = join_by(PUBLICSAMPLEID))

# The dataset includes both raw and generated variables. Generated variables
# created by the BFY study staff and are recommended for analysis because 
# they have been cleaned and are easier to use.
# Remove raw variables based on variable label
raw_label <- function(x) {
  grepl("\\[Raw\\]", attr(x, "label"))
}

# Remove variables with [raw] in label
# Convert variables to numeric
bfy <- bfy |>
  select(where(~ !raw_label(.))) |> 
  mutate(across(where(is.labelled), as.numeric))
```

## Data exploration

### Univariate analyses

```{r}
# Raincloud plot
bfy |> 
  ggplot(aes(1, CASQLANGA1)) + 
  geom_rain(boxplot.args = list(outlier.color = "red")) + 
  labs(y = "Standardized ASQ Communication Langauge Scores") + 
  scale_y_continuous(limits = c(-3.5, 3.5), breaks = seq(-3, 3, 1)) + 
  theme_classic() + 
  theme(
    axis.title.y = element_blank(),
    axis.text.y = element_blank(), 
    axis.ticks.y = element_blank()
  ) +
  coord_flip()
```

### Bivariate analyses

```{r}
# Bar chart
bfy |> 
  mutate(TREATA0 = factor(TREATA0)) |> 
  group_by(TREATA0) |> 
  summarize(mean = round(mean(CASQLANGA1, na.rm = TRUE), 3)) |> 
  ggplot(aes(x = TREATA0, y = mean, fill = TREATA0)) +
  geom_col(alpha = 0.5, width = 0.5) + 
  geom_text(aes(label = paste0(mean), hjust = -0.5)) +
  scale_y_continuous(limits = c(0, 0.7), breaks = seq(0, 0.7, 0.1)) + 
  labs(
    x = "Treatment group",
    y = "Standardized ASQ Communication Langauge Scores"
  ) +
  coord_flip() +
  theme_bw() +
  theme(legend.position = "none")
```

```{r}
# Bar chart
bfy |> 
  mutate(HHSNAPA0 = factor(HHSNAPA0)) |> 
  filter(!is.na(HHSNAPA0)) |> 
  group_by(HHSNAPA0) |> 
  summarize(mean = round(mean(CASQLANGA1, na.rm = TRUE), 3)) |> 
  ggplot(aes(x = HHSNAPA0, y = mean, fill = HHSNAPA0)) +
  geom_col(alpha = 0.5, width = 0.5) + 
  geom_text(aes(label = paste0(mean), hjust = -0.5)) +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) + 
  labs(
    x = "Household Receives Food Stamps",
    y = "Standardized ASQ Communication Langauge Scores"
  ) +
  coord_flip() +
  theme_bw() +
  theme(legend.position = "none")
```

```{r}
# Bar chart
bfy |> 
  mutate(MEDLEVELA0 = factor(MEDLEVELA0)) |> 
  filter(!is.na(MEDLEVELA0)) |> 
  group_by(MEDLEVELA0) |> 
  summarize(mean = round(mean(CASQLANGA1, na.rm = TRUE), 3)) |> 
  ggplot(aes(x = MEDLEVELA0, y = mean, fill = MEDLEVELA0)) +
  geom_col(alpha = 0.5, width = 0.5) + 
  geom_text(aes(label = paste0(mean), hjust = -0.5)) +
  scale_y_continuous(limits = c(0, 0.4), breaks = seq(0, 0.4, 0.05)) + 
  labs(
    x = "Mother's Highest Level of Education Attained",
    y = "Standardized ASQ Communication Langauge Scores"
  ) +
  coord_flip() +
  theme_bw() +
  theme(legend.position = "none")
```

## Model construction

### Training and Testing

```{r}
# Split data into training set (75%) and testing set (25%)
bfy_split <- initial_split(bfy)
bfy_train <- training(bfy_split)
bfy_test <- testing(bfy_split)
```

### Setting the formula and recipe

```{r}
# Define formula for linear regression
bfy_formula <- as.formula("CASQLANGA1 ~ .")

# Define pre-processing steps
bfy_enet_recipe <- bfy |> 
  recipe(bfy_formula) |> 
  update_role(CASQLANGA1, new_role = "outcome") |> 
  update_role(PUBLICSAMPLEID, new_role = "id") |>
  step_other(all_nominal_predictors(), threshold = 0.01) |> 
  step_dummy(all_nominal_predictors()) |> 
  step_filter_missing(all_predictors(), threshold = 0.1) |> 
  step_impute_mean(all_numeric_predictors()) |> 
  step_naomit(all_outcomes()) |> 
  step_zv(all_predictors()) |> 
  step_corr(all_predictors(), threshold = 0.95) |> 
  step_normalize(all_predictors())
```

```{r}
# Apply transformations on training set and look at results
bfy_enet_recipe |> prep() |> bake(bfy_train) |> head()
```

### Model specifications

```{r}
# Define model
bfy_enet_model <- 
  linear_reg(penalty = tune(), mixture = tune()) |> 
  set_engine("glmnet")
```

```{r}
# Set up workflow
bfy_enet_workflow <- 
  workflow() |> 
  add_model(bfy_enet_model) |> 
  add_recipe(bfy_enet_recipe)
```

## Hyperparameter training

```{r}
# Set up grid and default values for parameters
bfy_enet_regular_grid <- 
  grid_regular(
    extract_parameter_set_dials(bfy_enet_model), 
    levels = 500
  )
```

```{r}
# Monte Carlo resampling on training data
bfy_enet_resamples <- mc_cv(bfy_train, times = 25, prop = 0.75)
```

```{r}
# Run model on the resampled data or load model fit if already created
fit_model <- FALSE

if(fit_model){
  # Mark start time
  start_time <- Sys.time()
  
  # Run model on the resampled data
  bfy_enet_tune_results <- bfy_enet_workflow |> 
    tune_grid(
      resamples = bfy_enet_resamples, 
      grid = bfy_enet_regular_grid
    )

  # Save model fit
  bfy_enet_tune_results_path <- here("final_paper", "bfy_enet_tune_results.Rdata")
  save(bfy_enet_tune_results, file = bfy_enet_tune_results_path)
  
  # Mark end time
  end_time <- Sys.time()
  
  # Report run time
  end_time - start_time
  
} else {
  # Load model fit if already created
  bfy_enet_tune_results_path <- here("final_paper", "bfy_enet_fit.Rdata")
  load(bfy_enet_tune_results_path)
}
```

## Choosing the best model

```{r}
# Determine best combination of penalty and mixture for lowest rmse
bfy_enet_tune_results |> 
  collect_metrics() |> 
  filter(.metric == "rmse") |> 
  arrange(mean)
```

```{r}
# Plot 
bfy_enet_tune_results |> 
  collect_metrics() |> 
  mutate(mixture = as_factor(round(mixture, 2))) |> 
  filter(.metric == "rmse") |> 
  rename_with(~str_to_title(.)) |> 
  rename(RMSE = Mean) |>
  ggplot(aes(y = RMSE, x = Penalty, color = Mixture)) +
  geom_line()+
  facet_wrap(~ Mixture, nrow = 2) +
  theme_minimal()
```

```{r}
# Best parameters based on rmse
bfy_enet_best_params <- bfy_enet_tune_results |> 
  select_best(metric = "rmse")

bfy_enet_best_params
```

```{r}
# Finalize workflow
bfy_enet_final_workflow <- bfy_enet_final_workflow |>
  finalize_workflow(bfy_enet_best_params)
```

```{r}
# Apply finalized model on training set and then compare it with validation set
bfy_enet_final_model <- bfy_enet_final_workflow |> 
  last_fit(bfy_split)
```

```{r}
# Evaluate model performance
collect_metrics(bfy_enet_final_model)
```

```{r}
# Extract variable estimates
final_enet_model |> 
  extract_fit_parsnip() |>  
  tidy() |> 
  arrange(-estimate)
```

